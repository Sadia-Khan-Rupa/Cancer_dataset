{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_less(num):\n",
    "    if num - 18 < 0:\n",
    "        return num  \n",
    "    else:\n",
    "        return num - 18\n",
    "    \n",
    "def get_patch_from_list(lung_img, coords, window_size = 10):\n",
    "\tshape = lung_img.shape\n",
    "\toutput = []\n",
    "\tlung_img = lung_img + 1024\n",
    "\tfor i in range(len(coords)):\n",
    "\t\tpatch =   lung_img[coords[i][0] - 18: coords[i][0] + 18,\n",
    "\t\t\t\t\t\t   coords[i][1] - 18: coords[i][1] + 18,\n",
    "\t\t\t\t\t\t   coords[i][2] - 18: coords[i][2] + 18]\t\t\t   \n",
    "\t\toutput.append(patch)\n",
    "\treturn output\n",
    "\n",
    "'''\n",
    "Sample a random point from the image and return the coordinates. \n",
    "'''\n",
    "def get_point(shape):\n",
    "\tx = randint(64, shape[2] - 64)\n",
    "\ty = randint(64, shape[1] - 64)\n",
    "\tz = randint(20, shape[0] - 20)\n",
    "\treturn np.asarray([z, y, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "much_data = []\n",
    "def create_data(path, train_csv_path):\n",
    "    coords, trainY = [], []\n",
    "    with open(train_csv_path, 'rb') as f:\n",
    "        lines = f.readlines()\n",
    "        counter = 0\n",
    "        for line in lines:\n",
    "            row = line.decode().split(',')\n",
    "            \n",
    "            all_images = []\n",
    "            all_labels = []\n",
    "            \n",
    "            \n",
    "            if os.path.isfile(path + row[0] + '.mhd') == False:\n",
    "                continue\n",
    "\n",
    "            lung_img = sitk.GetArrayFromImage(sitk.ReadImage(path + row[0] + '.mhd'))\n",
    "\n",
    "            for i in range(-5, 5, 3):\n",
    "                for j in range(-5, 5, 3):\n",
    "                    for k in range(-2, 3, 2):\n",
    "                        coords.append([int(float(row[3])) + k, int(float(row[2])) + j, int(float(row[1])) + i])\n",
    "                        trainY.append(True)\n",
    "                        \n",
    "            for i in range(60):\n",
    "                coords.append(get_point(lung_img.shape))\n",
    "                trainY.append(False)\n",
    "\n",
    "            trainX = get_patch_from_list(lung_img, coords)\n",
    "            \n",
    "\n",
    "            \n",
    "            for elem,x in zip(trainX,trainY):\n",
    "                if elem.shape[0]==36 and elem.shape[1]==36 and elem.shape[2]==36:\n",
    "                    all_images.append(elem)\n",
    "                    all_labels.append(x)\n",
    "            \n",
    "\n",
    "            pickle.dump(np.asarray(all_images), open('F:\\models\\\\Cancer Dataset\\\\code\\\\nodule_2\\\\traindata_' + str(counter) + '_Xtrain.p', 'wb'))\n",
    "            pickle.dump(np.asarray(all_labels, dtype = bool),  open('F:\\\\models\\\\Cancer Dataset\\\\code\\\\nodule_2\\\\traindata_' + str(counter) + '_Ytrain.p', 'wb'))\n",
    "\n",
    "            counter = counter + 1\n",
    "            \n",
    "            coords, trainY = [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_data('F:\\\\models\\\\Cancer Dataset\\\\subset0\\\\subset0', 'F:\\\\models\\\\Cancer Dataset\\\\CSVFILES\\\\annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (1.14.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.27.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (45.2.0.post20200210)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: np_utils in c:\\programdata\\anaconda3\\lib\\site-packages (0.5.12.1)\n",
      "Requirement already satisfied: numpy>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from np_utils) (1.18.1)\n",
      "Requirement already satisfied: future>=0.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from np_utils) (0.18.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras \n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Convolution3D, MaxPooling3D\n",
    "'''from tensorflow.keras.utils import np_utils '''\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "'''\n",
    "Creates a keras model with 3D CNNs and returns the model.\n",
    "'''\n",
    "def classifier(input_shape, kernel_size, pool_size):\n",
    "\tmodel = Sequential()\n",
    "\n",
    "\tmodel.add(Convolution3D(16, kernel_size[0], kernel_size[1], kernel_size[2],\n",
    "\t                        border_mode='valid',\n",
    "\t                        input_shape=input_shape, data_format = 'channels_first'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling3D(pool_size=pool_size, data_format = 'channels_first') )\n",
    "\tmodel.add(Convolution3D(32, kernel_size[0], kernel_size[1], kernel_size[2], data_format = 'channels_first'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling3D(pool_size=pool_size, data_format = 'channels_first'))\n",
    "\tmodel.add(Convolution3D(64, kernel_size[0], kernel_size[1], kernel_size[2], data_format = 'channels_first'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(MaxPooling3D(pool_size=pool_size, data_format = 'channels_first'))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(128))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(Dropout(0.5))\n",
    "\tmodel.add(Dense(2))\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import pickle,sys\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Activation, Reshape\n",
    "\n",
    "def train_classifier(input_shape):\n",
    "    val_x = []\n",
    "    val_y = []\n",
    "    model = classifier(input_shape, (3, 3, 3), (2, 2, 2))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    for i in range(801,1186):\n",
    "        file_name = 'F:\\models\\\\Cancer Dataset\\\\code\\\\nodule_2\\\\traindata_'+str(i)+'_Xtrain.p'\n",
    "        f = open(file_name,'rb')\n",
    "        file_data = pickle.load(f)\n",
    "        \n",
    "        file_name_y = 'F:\\models\\\\Cancer Dataset\\\\code\\\\nodule_2\\\\traindata_'+str(i)+'_Ytrain.p'\n",
    "        f_y = open(file_name_y,'rb')\n",
    "        file_data_y = pickle.load(f_y)\n",
    "        for j in range(len(file_data)):\n",
    "            val_x.append(file_data[j].reshape(1,36,36,36))\n",
    "            #val_y.append(file_data_y[j])\n",
    "            if file_data_y[j] == True:\n",
    "                val_y.append([1,0])\n",
    "            else:\n",
    "                val_y.append([0,1])\n",
    "            \n",
    "    print(np.array(val_x).shape)\n",
    "    print(np.array(val_y).shape)\n",
    "    for i in range(224, 235):\n",
    "        train_x = []\n",
    "        train_y = []\n",
    "        file_name = 'F:\\models\\\\Cancer Dataset\\\\code\\\\nodule_2\\\\traindata_'+str(i)+'_Xtrain.p'\n",
    "        f = open(file_name,'rb')\n",
    "        file_data = pickle.load(f)\n",
    "        \n",
    "        file_name_y = 'F:\\models\\\\Cancer Dataset\\\\code\\\\nodule_2\\\\traindata_'+str(i)+'_Ytrain.p'\n",
    "        f_y = open(file_name_y,'rb')\n",
    "        file_data_y = pickle.load(f_y)\n",
    "        \n",
    "        for j in range(len(file_data)):\n",
    "            #train_x.append(Reshape((36,36,36) + (1,),input_shape = (36,36,36))(np.ndarray.tolist(file_data[j])))\n",
    "            train_x.append(file_data[j].reshape((1,36,36,36)))\n",
    "            if file_data_y[j] == True:\n",
    "                train_y.append([1,0])\n",
    "            else:\n",
    "                train_y.append([0,1])\n",
    "        \n",
    "        #x = Reshape(input_shape + (1, ), input_shape=input_shape)(inputs)\n",
    "        model.train_on_batch(np.array(train_x), np.array(train_y), sample_weight=None)\n",
    "        print('network trained')\n",
    "        \n",
    "        \n",
    "        \n",
    "        val_x = val_x[:108]\n",
    "        for num in range(0,len(val_x),108):\n",
    "            print('accuracy for test is ')\n",
    "            print (model.test_on_batch(np.array(val_x[num:num + 108]), np.array(val_y[num:num+108]), sample_weight=None))\n",
    "        \n",
    "    model.save('F:\\models\\\\Cancer Dataset\\\\code\\\\nodule_2\\\\model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
